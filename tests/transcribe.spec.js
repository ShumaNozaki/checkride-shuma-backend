// éŸ³å£°èªè­˜ã®å˜ä½“ãƒ†ã‚¹ãƒˆ
// POST /transcribe ãŒæ­£ã—ãæ–‡å­—èµ·ã“ã—ãƒ»ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºã‚’è¡Œã†ã‹ã‚’ãƒ†ã‚¹ãƒˆ

const express = require('express');
require('dotenv').config();

// APIæŽ¥ç¶š
const SpeechToTextV1 = require('ibm-watson/speech-to-text/v1');
const { IamAuthenticator } = require('ibm-watson/auth');

const request = require('supertest');

const path = require('path');
const router = require('../routes/speechtotext');

// ãƒ†ã‚¹ãƒˆã‚ˆã†ã«ã‚µãƒ¼ãƒãƒ¼ã‚’ä½œæˆ
const app = express();
app.use(express.json());
app.use('/', router);

describe('POST /transcribe', () => {
  it('APIãŒã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å—ã‘å–ã‚Šã€æŠ½å‡ºçµæžœã‚’è¿”ã™ã“ã¨', async () => {
    const audioPath = path.join(__dirname, 'ja-JP_Broadband-sample.wav'); // ãƒ†ã‚¹ãƒˆç”¨ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«
    const keywords = 'éŸ³å£°,ãƒ‡ã‚£ãƒ¼ãƒ—';

    console.log()

    const response = await request(app)
      .post('/transcribe')
      .field('keywords', keywords)
      .field('language', 'ja')
      .attach('audio', audioPath);

    // ãƒ‡ãƒãƒƒã‚¯å‡ºåŠ›
    console.log('ðŸ“„ Transcript:', response.body.transcript);
    console.log('ðŸ” Matches:', response.body.matches);

    // ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ¤œè¨¼
    expect(response.statusCode).toBe(200);
    expect(response.body).toHaveProperty('transcript');
    expect(response.body).toHaveProperty('matches');
    expect(Array.isArray(response.body.matches)).toBe(true);

    // ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒæ­£ã—ãæŠ½å‡ºã•ã‚Œã¦ã„ã‚‹ã‹
    const matchKeywords = response.body.matches.map(m => m.keyword);
    expect(matchKeywords).toEqual(expect.arrayContaining(['éŸ³å£°', 'ãƒ‡ã‚£ãƒ¼ãƒ—']));}, 15000); // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ15ç§’
  });
